---
permalink: /
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

<!-- ![ ](https://jiazhaoli.github.io/images/avatar.jpg) -->


# About Me
I am Jiazhao Li, an Applied Scientist on the Rufus team within Amazonâ€™s Store Fundamental AI Post-Training group. I earned my Ph.D. from the School of Information at the University of Michigan, Ann Arbor, where I was advised by Prof. [V.G.Vinod Vydiswaran](http://www-personal.umich.edu/~vgvinodv/). I also collaborate with Prof. [Chaowei Xiao](https://xiaocw11.github.io/) on research in Trustworthy AI.


# Research
My research interests are Truthworthy AI (red-teaming, backdoor attack & defense of LLMs), Generative models, Health informatics.

# Education

* Ph.D. in Informatics, University of Michigan , 2020 - 2024 
* M.S. in Electrical Computer Engineering, University of Michigan, 2017 - 2019
* B.S. in Electrical Engineering, Nankai University, China, 2013 - 2017

# Industry Experience
* 11/2024 - present : Applied Scientist @ Amazon
* 05/2023 - 08/2023 : Research Scientiest Intern @ Yahoo Research
* 10/2019 - 08/2020 : Research Associate @ Michigan Medicine


<!-- # Teaching Experience
  Graduate Student Instructor:<br>
 * WN 2024: SI 630 Natura Language Processing Algorithms and People. <br>
 * WN 2023: LHS 712 Natural Language Processing for Health. <br> -->

<!-- # Public Service

 * <b>Reviewer or PC of conference</b>: ACL ARR, EACL 2023, EMNLP 20'21'22'23<br>
 * <b>Reviewer of Journal</b>: Frontiers in Big Data, section Cybersecurity and Privacy. <br> -->

<!-- # Awards 

 * Rackham Conference Travel Grant <br>
 * UMSI Conference Travel Grant <br> -->

# Selected Publications

* [Truthworthy AI] Benchmarking vision language model unlearning via fictitious facial identity dataset [[Paper]](https://arxiv.org/pdf/2411.03554) <br>
Yingzi Ma, Jiongxiao Wang, Fei Wang, Siyuan Ma, Jiazhao Li, Jinsheng Pan, Xiujun Li, Furong Huang, Lichao Sun, Bo Li, Yejin Choi, Muhao Chen, Chaowei Xiao <br>
<i>ICLR 2025</i>.<br>

* [Truthworthy AI] Mitigating Fine-tuning Jailbreak Attack with Backdoor Enhanced Alignment [[Paper]](https://arxiv.org/abs/2402.14968) <br> 
Jiongxiao Wang, <b>Jiazhao Li</b>, Yiquan Li, Xiangyu Qi, Muhao Chen, Junjie Hu, Yixuan Li, Bo Li, and Chaowei Xiao <br>
<i>NeurIPS 2024</i>.<br>


* [Truthworthy AI] ChatGPT as an Attack Tool: Stealthy Textual Backdoor Attack via Blackbox Generative Model Trigger. [[Paper]](https://aclanthology.org/2024.naacl-long.165.pdf) <br> 
<b>Jiazhao Li</b>, Yijin Yang, Zhuofeng Wu, V.G. Vinod Vydiswaran, Chaowei Xiao <br>
<i>NAACL 2024, Spotlight Paper of 4th TrustNLP workshop</i>.<br>


* [Truthworthy AI] Defending against Insertion-based Textual Backdoor Attacks via Attribution. [[Paper]](https://aclanthology.org/2023.findings-acl.561/) <br> 
<b>Jiazhao Li</b>, Zhuofeng Wu, Wei Ping, Chaowei Xiao, V.G.Vinod Vydiswaran <br>
<i>Findings of ACL 2023</i>.<br>

* [Machine Translation] PharmMT: A Neural Machine Translation Approach to Simplify Prescription Directions. [[Paper]](https://www.aclweb.org/anthology/2020.findings-emnlp.251.pdf) [[BibTex]](https://jiazhaoli.github.io/files/2020/EMNLP/PharmMT.txt)[[Video]](https://slideslive.com/38940180/pharmmt-a-neural-machine-translation-approach-to-simplify-prescription-directions?) <br> 
<b>Jiazhao Li</b>, Corey Lester, Xinyan Zhao, Yuting Ding, Yun Jiang, and V.G.Vinod Vydiswaran. <br>
<i>Findings of EMNLP 2020</i>.<br>


* [Information Retrieval] Re-ranking biomedical literature for precision medicine with pre-trained neural models. [[Paper]](https://jiazhaoli.github.io/files/2020/ICHI/ICHI2020_Re-ranking.pdf) [[BibTex]](https://jiazhaoli.github.io/files/2020/ICHI/ICHI.txt)<br>
<b>Jiazhao Li</b>, Adharsh Murali, Qiaozhu Mei, V.G.Vinod Vydiswaran. <br>
<i>ICHI 2020</i>.<br>





<!---Experience--->
